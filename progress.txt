## Codebase Patterns
- Claude Code custom skills go in `.claude/commands/<skill-name>.md` at project root
- Monorepo uses Turborepo with `apps/` and `packages/` workspaces
- Existing Python demo-recorder in `packages/demo-recorder/` — PRD requires TypeScript-only for core flow
- Project uses npm (not yarn/pnpm), see `package-lock.json`
- Quality checks: `turbo run build`, `turbo run lint`, `turbo run check-types`
- New Node.js packages: extend `@repo/typescript-config/base.json`, add `eslint.config.js` with `@repo/eslint-config/base`, set `type: "module"`
- Core utilities live in `packages/core/src/` — import with `@repo/core` or `@repo/core/<module>`
- ESLint `--max-warnings 0` means NO unused vars allowed (even with `_` prefix) — remove unused params entirely
- Convex backend lives in `apps/web/convex/` — schema in `schema.ts`, functions in `runs.ts`
- Convex `_generated/` uses `GenericDataModel` — cast query results to app types on the client side
- Exclude `convex/_generated/**` in ESLint config to avoid lint errors on auto-generated files
- Dashboard UI at `apps/web/` — strict B&W theme, sharp edges, CSS Modules, responsive grid
- Upload utility in `packages/core/src/convex-uploader.ts` — uses Convex HTTP API for uploads from CLI/pipeline
- PR bot in `packages/core/src/pr-bot.ts` — single persistent comment with `<!-- aura-bot -->` marker, status lifecycle
- Daytona sandbox orchestration in `packages/core/src/sandbox.ts` — create/exec/export/destroy lifecycle

---

## 2026-02-28 - US-001
- Created `/record-demo` Claude Code skill at `.claude/commands/record-demo.md`
- Skill is discoverable via `/record-demo` command (confirmed in skill listing)
- Contains full placeholder prompt structure: diff analysis, web app detection, dev server startup, browser-use recording, Screen Studio-style post-processing, and output reporting
- TypeScript-only baseline — no Python runtime dependency in the skill prompt
- Files changed: `.claude/commands/record-demo.md` (new)
- **Learnings for future iterations:**
  - Claude Code discovers skills from `.claude/commands/` directory automatically
  - The skill appears in the available skills list immediately after file creation
  - Existing `packages/plugin/skills/record-demo/SKILL.md` is the old Python-based version; the new `.claude/commands/record-demo.md` supersedes it
  - PRD says `~/.claude/commands/` (home dir) but project-level `.claude/commands/` is correct for project-scoped skills
---

## 2026-02-28 - US-002
- Created `@repo/core` package at `packages/core/` with TypeScript utilities
- `diff-analyzer.ts`: parses `git diff --name-status`, classifies files as component/page/route, deduplicates
- `web-app-detector.ts`: reads `package.json`, detects framework (Next.js, React, Vue, Vite, Angular, Svelte, Nuxt, Remix, Astro), finds dev script and port
- `route-inferrer.ts`: infers affected routes from changed file paths with confidence levels (high/medium/low), supports Next.js App Router, Pages Router, and generic patterns
- `index.ts`: re-exports all public APIs and types
- Updated `.claude/commands/record-demo.md` skill with detailed Step 1 instructions for diff analysis, web app detection, and route inference
- Files changed: `packages/core/` (new package), `.claude/commands/record-demo.md` (updated), `package-lock.json`
- **Learnings for future iterations:**
  - New packages need `eslint.config.js` importing from `@repo/eslint-config/base` for lint to work
  - Use `@repo/typescript-config/base.json` (not react-library) for Node.js-only packages
  - Package `type: "module"` and `.js` extensions in imports are required for NodeNext module resolution
  - The `parseDiffNameStatus` function is exported separately so it can be unit-tested without git
  - Route inference confidence levels help the browser agent prioritize which routes to visit
---

## 2026-02-28 - US-003
- Created `dev-server.ts` in `packages/core/src/` with dev server lifecycle management
- `startDevServer()`: spawns dev process in background, polls for HTTP readiness, returns handle with kill()
- `httpCheck()`: single HTTP GET probe to localhost port
- `waitForPort()`: polls with configurable timeout (default 60s) and interval (default 500ms)
- `findActivePort()`: scans common ports (3000, 5173, 8080, 4200, 4321, 8000) as fallback
- `resolveDevCommand()`: derives `npm run <script>` from WebAppInfo
- Handles already-running servers (returns no-op handle)
- Uses `detached: true` + process group kill for clean cleanup
- Updated skill prompt Step 2 with detailed server startup instructions
- Files changed: `packages/core/src/dev-server.ts` (new), `packages/core/src/index.ts` (updated), `.claude/commands/record-demo.md` (updated)
- **Learnings for future iterations:**
  - Use `process.kill(-pid, 'SIGTERM')` for process group cleanup (negative PID kills the group)
  - Set `FORCE_COLOR=0` env var to avoid ANSI escapes in captured output
  - Always check if port is already in use before spawning — avoids double-server issues
  - `detached: true` with `stdio: ["ignore", "pipe", "pipe"]` prevents zombie processes
---

## 2026-02-28 - US-004
- Created `browser-recorder.ts` in `packages/core/src/` with recording session orchestration
- `createSession()`: initializes recording session with ID, routes, output dir
- `createOutputDir()`: creates `demos/[timestamp]/screenshots/` structure
- `addStep()`: logs actions (navigate, click, type, screenshot) with timestamps
- `buildNavigationScript()`: converts InferredRoute[] to full URL list
- `writeSummary()`: generates `summary.md` with routes, steps, and diff context
- `buildLaminarMetadata()`: prepares Laminar tracing config for browser-use runs
- `buildSupermemoryQuery()`: prepares Supermemory context retrieval query
- Updated skill prompt Step 3 with detailed browser-use + Playwright instructions
- Files changed: `packages/core/src/browser-recorder.ts` (new), `packages/core/src/index.ts` (updated), `.claude/commands/record-demo.md` (updated)
- **Learnings for future iterations:**
  - browser-use npm package is built on Playwright — use Playwright directly for screenshots/video recording
  - Playwright `recordVideo: { dir, size }` in context options auto-saves video on context close
  - browser-use Agent takes `{ task, llm }` — configure with routes and diff context as the task description
  - Laminar and Supermemory are optional integrations — gate on env vars (LAMINAR_ENDPOINT, SUPERMEMORY_ENDPOINT)
  - Session ID format YYYYMMDD-HHMMSS doubles as the demos/ subfolder name
---

## 2026-02-28 - US-005
- Created `interaction-planner.ts` in `packages/core/src/` for AI-driven interaction planning
- `extractInteractiveElements()`: parses diff hunks for added HTML/JSX elements (button, input, form, etc.), ARIA roles, and event handlers (onClick, onSubmit, onChange)
- Smart selector extraction with priority: id > data-testid > aria-label > className > text content > tag fallback
- `generateInteractionPlan()`: maps elements to routes, deduplicates, sorts by confidence then action type, returns structured step list
- Graceful handling: missing elements are skipped without failing the recording
- Updated skill prompt Step 4 with detailed interaction plan generation and execution instructions
- Files changed: `packages/core/src/interaction-planner.ts` (new), `packages/core/src/index.ts` (updated), `.claude/commands/record-demo.md` (updated)
- **Learnings for future iterations:**
  - Use global regex patterns with `lastIndex = 0` reset before each test to avoid missed matches
  - Selector extraction from JSX is best-effort — data-testid is the most reliable
  - Event handler detection (onClick etc.) serves as a fallback when no HTML element is directly visible in the diff
  - Diff hunks keyed by file path allow mapping elements back to their source route
  - Wait times vary by action: 500ms for clicks, 2000ms for form submissions
---

## 2026-02-28 - US-006
- Created `video-processor.ts` in `packages/core/src/` for Screen Studio-style post-processing
- `interpolateCursorPath()`: cubic bezier interpolation between cursor keyframes, deterministic output
- `generateZoomKeyframes()`: creates zoom-in effects on click/type actions
- `getZoomAtTime()`: frame-level zoom with asymmetric easing (30% zoom-in, 70% zoom-out)
- Three style presets: default (balanced), minimal (subtle), dramatic (deep zoom + dark bg)
- `buildFFmpegCompositeCommand()`: generates FFmpeg command for H.264 MP4 with cursor overlay + zoom
- `prepareVideoProcessing()`: full pipeline — builds cursor path, zoom keyframes, manifest, FFmpeg command
- `writeRenderManifest()`: writes render-manifest.json with all processing metadata
- Updated skill prompt Step 5 with detailed post-processing instructions
- Files changed: `packages/core/src/video-processor.ts` (new), `packages/core/src/index.ts` (updated), `.claude/commands/record-demo.md` (updated)
- **Learnings for future iterations:**
  - ESLint in this project treats `_` prefixed unused params as warnings too — remove unused params entirely instead
  - Cubic bezier with control points along x-axis only produces natural horizontal cursor arcs
  - Asymmetric zoom (fast in, slow out) feels more natural than symmetric — use 30/70 split
  - FFmpeg `-movflags +faststart` is essential for web playback (moves moov atom to start)
  - `zoompan` filter in FFmpeg can do per-frame zoom but syntax is complex for dynamic keyframes
  - Render manifest JSON captures all processing metadata for debugging and reproducibility
---

## 2026-02-28 - US-007
- Created Convex backend for dashboard: schema with `runs` table (indexes: by_timestamp, by_status, by_branch)
- Convex functions: `list`, `get`, `create`, `updateStatus`, `attachVideo`, `attachScreenshots`, `generateUploadUrl`
- Dashboard homepage (`apps/web/app/page.tsx`): grid of run cards with status badges, video thumbnails, route chips
- Run detail page (`apps/web/app/runs/[runId]/page.tsx`): video player, metadata grid, summary, screenshots, error display
- Strict black-and-white visual theme with sharp edges (border-radius: 0), no color gradients
- Responsive layout: 3-col desktop, 2-col tablet, 1-col mobile via CSS Grid `auto-fill`
- ConvexClientProvider wraps the app in layout.tsx
- Created `convex-uploader.ts` in `packages/core/src/` for pipeline uploads via Convex HTTP API
- Updated skill prompt with Step 5f (upload to dashboard) and dashboard link in output
- Excluded `convex/_generated/**` from ESLint to avoid warnings on auto-generated files
- Files changed: `apps/web/convex/` (new), `apps/web/app/` (rewritten), `apps/web/eslint.config.js`, `apps/web/package.json`, `packages/core/src/convex-uploader.ts` (new), `packages/core/src/index.ts`, `.claude/commands/record-demo.md`, `package-lock.json`
- **Learnings for future iterations:**
  - Convex `_generated/server.d.ts` uses `GenericDataModel` — query return types lose schema info, so cast to app-defined types on the client
  - Use `RegisteredMutation` type annotation for mutations with inferred return types that reference internal Convex types (avoids TS2742)
  - Convex storage upload flow: generate upload URL via mutation → POST file to URL → get storageId → attach to document
  - Next.js 16 uses `params: Promise<...>` for dynamic routes — unwrap with `use(props.params)`
  - CSS Modules `composes` works for badge variants but the composed class must be defined in the same file
  - Convex local dev runs on port 3210 (HTTP API) and 3211 (site URL)
  - Root `convex/` directory is created by `npx convex dev` when run from monorepo root — don't commit it
---

## 2026-02-28 - US-008
- Updated skill prompt Step 5g to explicitly require dashboard link in Claude's response
- Response format now mandates: dashboard URL (specific run, not root), short summary, routes tested, local file paths
- `createRun()` from `@repo/core/convex-uploader` already returns `{ runId, dashboardUrl }` with `/runs/<runId>` path
- Added graceful fallback: if upload fails, still report local files with error note
- Files changed: `.claude/commands/record-demo.md`
- **Learnings for future iterations:**
  - The skill prompt is the single source of truth for Claude's response format — be explicit about what must appear
  - `dashboardUrl` from `createRun()` already contains the full specific-run URL — no need to construct it separately
---

## 2026-02-28 - US-009
- Created `pr-bot.ts` in `packages/core/src/` for GitHub PR comment lifecycle management
- `findExistingComment()`: searches PR comments for the `<!-- aura-bot -->` marker to find the canonical bot comment
- `postOrUpdateComment()`: creates or edits the single persistent comment (avoids comment spam)
- `updateCommentStatus()`: transitions comment through status lifecycle (queued → running → uploading → completed/failed)
- `buildCommentBody()`: renders markdown comment body with status, video preview, dashboard link, summary, and routes tested
- Comment body uses a hidden HTML marker (`<!-- aura-bot -->`) for identification
- Status-specific rendering: queued/running show spinner text, completed shows video + dashboard link + summary, failed shows error
- Files changed: `packages/core/src/pr-bot.ts` (new), `packages/core/src/index.ts` (updated)
- **Learnings for future iterations:**
  - GitHub API uses `issues/comments` endpoint for PR comments (PRs are issues)
  - Hidden HTML comments (`<!-- marker -->`) are the standard pattern for bot comment identification
  - Always use `per_page=100` when searching for existing comments to avoid pagination issues on busy PRs
  - The `X-GitHub-Api-Version` header is recommended for API stability
---

## 2026-02-28 - US-010
- Created `sandbox.ts` in `packages/core/src/` for Daytona sandbox orchestration
- `createSandbox()`: spawns Daytona workspace with repo, branch, image, and env vars
- `runInSandbox()`: executes commands inside sandbox with output capture and artifact parsing
- `exportArtifact()`: copies files from sandbox to local path via `daytona cp`
- `destroySandbox()`: best-effort cleanup via `daytona delete --force`
- `runPipeline()`: sequential multi-step execution with early exit on failure
- `buildRecordingPipelineSteps()`: standard recording pipeline (install, browsers, build, record)
- Pipeline is resumable — run state metadata lives in Convex, sandbox is stateless
- Falls back gracefully when `daytona` CLI is not available (sandbox status = "failed")
- Files changed: `packages/core/src/sandbox.ts` (new), `packages/core/src/index.ts` (updated)
- **Learnings for future iterations:**
  - Daytona CLI uses `daytona create/exec/cp/delete` subcommands
  - Use `maxBuffer: 50MB` for exec to handle large build outputs
  - Parse artifact paths from stdout using regex pattern matching on "artifact:", "output:", etc.
  - Best-effort cleanup pattern: wrap destroy in try/catch, never throw on cleanup failure
---

## 2026-02-28 - US-011
- Created `laminar.ts` in `packages/core/src/` for OpenTelemetry-compatible tracing
- `createTrace()`, `startSpan()`, `endSpan()`, `addSpanEvent()`, `endTrace()`: full trace lifecycle
- `exportTrace()`: sends OTLP-formatted trace data to Laminar endpoint
- `buildTraceUrl()`: constructs deep-link URL to trace in Laminar UI
- `getLaminarConfig()`: reads from `LAMINAR_ENDPOINT`, `LAMINAR_API_KEY`, `LAMINAR_PROJECT_ID` env vars
- Added all env vars to `turbo.json` `globalEnv` to satisfy `turbo/no-undeclared-env-vars` lint rule
- Files changed: `packages/core/src/laminar.ts` (new), `packages/core/src/index.ts`, `turbo.json`
- **Learnings for future iterations:**
  - Turbo's `turbo/no-undeclared-env-vars` lint rule requires all `process.env` references to be in `turbo.json` `globalEnv`
  - Add env vars proactively for upcoming modules (Supermemory, AgentMail, etc.) to avoid repeated turbo.json edits
  - OTLP trace format uses nanosecond timestamps (multiply ms by 1_000_000)
---

## 2026-02-28 - US-012
- Created `supermemory.ts` in `packages/core/src/` for cross-run context persistence
- `storeRunContext()`: stores run summary, routes, components into Supermemory via API
- `retrieveContext()`: semantic search for relevant prior runs by branch, routes, or components
- `mergeContextIntoPrompt()`: appends retrieved context as structured prompt section
- `getSupermemoryConfig()`: reads from `SUPERMEMORY_ENDPOINT`, `SUPERMEMORY_API_KEY` env vars
- Retrieval can be disabled by not setting env vars (returns empty context gracefully)
- Files changed: `packages/core/src/supermemory.ts` (new), `packages/core/src/index.ts`
- **Learnings for future iterations:**
  - Re-exported as `SupermemoryClientConfig` to avoid collision with existing `SupermemoryConfig` from browser-recorder
  - Supermemory search API uses similarity scoring — merge into prompt sorted by relevance
---

## 2026-02-28 - US-013
- Created `agentmail.ts` in `packages/core/src/` for email delivery via AgentMail API
- `sendEmail()`: sends HTML+text email with dashboard URL, video link, PR references, summary
- `getAgentMailConfig()`: reads from `AGENTMAIL_API_KEY`, `AGENTMAIL_FROM` env vars
- Email includes status-specific content (completed: video+summary, failed: error details)
- Delivery failures return structured `SendResult` with error message (never throws)
- For PR-triggered runs, email includes PR link and bot comment link
- Files changed: `packages/core/src/agentmail.ts` (new), `packages/core/src/index.ts`
- **Learnings for future iterations:**
  - AgentMail API endpoint is `https://api.agentmail.to/v1/messages`
  - Always send both HTML and text versions for email compatibility
  - Return structured error results instead of throwing — caller decides how to handle delivery failures
---

## 2026-02-28 - US-014
- Created `edits.ts` in `apps/web/convex/` with full editing API: crop, trim, split, zoom, cursor_emphasis, style_preset operations
- Added `editVersions` table to Convex schema with indexes by_run and by_status
- Operations are non-destructive: each edit creates a new version with parent chain, operations accumulate
- Revert creates a version 0 with empty operations to restore original
- Editor UI at `apps/web/app/runs/[runId]/edit/page.tsx`: tabbed interface for each operation, version history, preview
- Run detail page now has "Edit" link for completed runs
- Files changed: `apps/web/convex/edits.ts` (new), `apps/web/convex/schema.ts`, `apps/web/convex/_generated/api.d.ts`, `apps/web/app/runs/[runId]/edit/page.tsx` (new), `apps/web/app/runs/[runId]/edit/page.module.css` (new), `apps/web/app/runs/[runId]/page.tsx`
- **Learnings for future iterations:**
  - Use `Value` type from `convex/values` for generic arrays stored in Convex (not `unknown[]`)
  - Destructure mutation args explicitly when patching to avoid `Record<string, unknown>` not assignable to `PatchValue` errors
  - Version numbering via count of existing versions + 1 is simple but not idempotent — acceptable for this use case
  - CSS Modules `composes` for button variants keeps styling DRY across edit panels
---

## 2026-02-28 - US-015
- Created `exports.ts` in `apps/web/convex/` with export job CRUD: create, list, get, updateProgress, complete, fail
- Added `exportJobs` table to Convex schema with indexes by_run and by_status
- Export page at `apps/web/app/runs/[runId]/export/page.tsx`: format (MP4/GIF), quality presets (preview/web/high), FPS (24/30/60), resolution (480p/720p/1080p), optional max file size
- Export jobs list shows progress bars, status badges, ETA, file size, download links, and error messages
- Run detail page now has "Export" link alongside "Edit" for completed runs
- Added `ExportJob` type to `apps/web/app/types.ts`
- Updated `_generated/api.d.ts` to include exports module
- Files changed: `apps/web/convex/exports.ts` (new), `apps/web/convex/schema.ts`, `apps/web/convex/_generated/api.d.ts`, `apps/web/app/types.ts`, `apps/web/app/runs/[runId]/page.tsx`, `apps/web/app/runs/[runId]/export/page.tsx` (new), `apps/web/app/runs/[runId]/export/page.module.css` (new)
- **Learnings for future iterations:**
  - Use nullish coalescing (`?? RESOLUTION_OPTIONS[0]`) for array index access to satisfy strict TS checks
  - Export jobs follow the same pattern as run status lifecycle but with their own progress/ETA tracking
  - Convex storage URLs for export outputs are resolved at query time using `ctx.storage.getUrl()`
---

## 2026-02-28 - US-016
- Created `aws-pipeline.ts` in `packages/core/src/` for AWS MediaConvert-backed video processing
- `getAWSPipelineConfig()` / `isAWSAvailable()`: reads AWS env vars, returns null when unavailable (enables fallback)
- `buildMediaConvertJobSpec()`: constructs full MediaConvert job JSON with codec settings, quality presets, HW acceleration
- `submitTranscodeJob()` / `pollJobStatus()`: HTTP-based job submission and polling (no AWS SDK dependency)
- `runTranscodeJob()`: full lifecycle with polling and status callbacks for streaming progress to dashboard
- `processVideoJob()`: top-level entrypoint with retry logic (up to 3 retries) and automatic local FFmpeg fallback
- `estimateCost()` / `buildTelemetry()`: per-job cost estimation and telemetry capture
- `buildLocalFallbackCommand()`: generates FFmpeg command for local/Daytona processing when AWS is unavailable
- `shouldRetry()` / `buildDeadLetterMessage()`: dead-letter handling with non-retryable error detection
- Quality presets map to codec settings: preview (H.264 CBR), web (H.264 QVBR), high (H.265 QVBR)
- Added AWS env vars to `turbo.json` `globalEnv`
- Files changed: `packages/core/src/aws-pipeline.ts` (new), `packages/core/src/index.ts`, `turbo.json`
- **Learnings for future iterations:**
  - AWS MediaConvert REST API at `/2017-08-29/jobs` — can be called with HTTP fetch (no SDK needed)
  - `IdempotencyToken` in job spec ensures duplicate submissions are safely deduplicated
  - For GIF output, use `FrameCaptureSettings` instead of codec settings, cap FPS at 15
  - `MoovPlacement: PROGRESSIVE_DOWNLOAD` is the MediaConvert equivalent of `-movflags +faststart`
  - Cost estimation: basic tier ~$0.012/min (SD), professional ~$0.048/min (HD)
  - Fallback pattern: check config → null means no AWS → fall back to local FFmpeg
---

## 2026-02-28 - US-017
- Created `apps/webhook/` as a standalone Node.js HTTP server (no framework dependency)
- `server.ts`: HTTP server handling GitHub webhook events at `/webhook` and health checks at `/health`
- Handles `pull_request` (opened/synchronize/reopened) and `issue_comment` (for `/aura re-run` commands)
- `verify.ts`: HMAC-SHA256 signature verification using `x-hub-signature-256` header
- `dispatch.ts`: Job dispatch lifecycle — creates Convex run, posts PR bot comment, transitions status
- `retryJob()`: Re-creates a new run for the same PR (triggered by `/aura re-run` comment)
- Accepts `ping` events for GitHub App configuration verification
- Deployable as standalone service (Fly.io, Railway, AWS) — listens on `PORT` env var (default 3001)
- Added webhook env vars (`GITHUB_WEBHOOK_SECRET`, `DASHBOARD_BASE_URL`, `PORT`) to `turbo.json` `globalEnv`
- Files changed: `apps/webhook/` (new app), `turbo.json`, `package-lock.json`
- **Learnings for future iterations:**
  - `createRun()` signature is `(options: ConvexUploaderOptions, metadata: RunMetadata)` — options first, metadata second
  - `postOrUpdateComment()` takes `(options: PRBotOptions, context: PRContext, state: CommentState)` — 3 args
  - `updateCommentStatus()` updates field is `Partial<Pick<CommentState, "summary" | "routesTested" | "videoUrl" | "dashboardUrl" | "error">>` — does NOT include `runId`
  - New monorepo apps need `npm install` to register them in workspaces before turbo can find them
  - Add `dist/**` to turbo build outputs for tsc-compiled apps alongside `.next/**`
---
